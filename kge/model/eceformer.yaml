import: [lookup_embedder]

eceformer:
  transformer_impl: pytorch
  use_preln: false
  use_rat: false
  dim: -1
  nlayer: 2
  nhead: 2

  # default values match the same number in pytorch implementation
  ff_dim: 2048 # transformer FFN dimension
  hidden_dropout: 0.1 # transformer hidden dropout
  attn_dropout: 0.1 # transformer attention dropout
  ctx_dropout: 0.5 # neighbor discrete dropout
  output_dropout: 0.0 # entity embedding dropout in output
  rel_dropout: 0.0
  self_dropout: 0.0
  mlm_mask: 0.6
  mlm_replace: 0.3
  add_mlm_loss: true
  activation: relu
  max_context_size: 0
  similarity: DotProduct
  initializer_range: 0.02 # transformer Linear and Embedding weight normal distribution std
  class_name: ECEformer
  entity_embedder:
    type: lookup_embedder
    +++: +++
  relation_embedder:
    type: lookup_embedder
    +++: +++
  time_embedder:
    type: lookup_embedder
    +++: +++
evokg:
  graph: ICEWS_500
  optimize: edge
  time_interval_log_transform: true
  static_entity_embed_dim: 200
  structural_dynamic_entity_embed_dim: 200
  temporal_dynamic_entity_embed_dim: 200
  embedding_updater_structural_gconv: RGCN+RNN
  embedding_updater_temporal_gconv: RGCN+RNN
  rel_embed_dim: 200
  num_gconv_layers: 2
  num_rnn_layers: 1
  dropout: 0.0
  embedding_updater_activation: tanh
  static_dynamic_combine_mode: concat
  combiner_gconv: none
  combiner_activation: tanh
  num_mix_components: 128
  inter_event_time_mode: node2node_inter_event_times
  log_dir: evokg_linkpred_seed339
  rnn_truncate_every: 40
  lr: 0.001
  weight_decay: 0.00001
  eval: edge
  full_link_pred_validation: true
  time_pred_eval: false